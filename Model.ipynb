{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842247ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HGTConv, global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Dataset\n",
    "\n",
    "class HeteroGraphDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root)\n",
    "        self.root = root\n",
    "        self.file_list = [f for f in os.listdir(root) if f.endswith('.pt')]\n",
    "        self.file_list.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(self.root, self.file_list[idx])\n",
    "        return torch.load(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975c471",
   "metadata": {},
   "source": [
    "The following is the domain generalization dataset partitioning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf100b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Modify to your path\n",
    "dataset1 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX\")\n",
    "dataset2 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX2\")\n",
    "dataset3 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX3\")\n",
    "\n",
    "train_len1 = int(0.7 * len(dataset1))\n",
    "val_len1 = int(0.15 * len(dataset1))\n",
    "test_len1 = len(dataset1) - train_len1 - val_len1\n",
    "\n",
    "train_len2 = int(0.7 * len(dataset2))\n",
    "val_len2 = int(0.15 * len(dataset2))\n",
    "test_len2 = len(dataset2) - train_len2 - val_len2\n",
    "\n",
    "train_len3 = int(0.7 * len(dataset3))\n",
    "val_len3 = int(0.15 * len(dataset3))\n",
    "test_len3 = len(dataset3) - train_len3 - val_len3\n",
    "\n",
    "train_set1, val_set1, test_set1 = random_split(dataset1, [train_len1, val_len1, test_len1], generator=torch.Generator().manual_seed(42))\n",
    "train_loader1 = DataLoader(train_set1, batch_size=8, shuffle=True)\n",
    "val_loader1 = DataLoader(val_set1, batch_size=8)\n",
    "test_loader1 = DataLoader(test_set1, batch_size=8)\n",
    "\n",
    "train_set2, val_set2, test_set2 = random_split(dataset2, [train_len2, val_len2, test_len2], generator=torch.Generator().manual_seed(42))\n",
    "train_loader2 = DataLoader(train_set2, batch_size=8, shuffle=True)\n",
    "val_loader2 = DataLoader(val_set2, batch_size=8)\n",
    "test_loader2 = DataLoader(test_set2, batch_size=8)\n",
    "\n",
    "train_set3, val_set3, test_set3 = random_split(dataset3, [train_len3, val_len3, test_len3], generator=torch.Generator().manual_seed(42))\n",
    "train_loader3 = DataLoader(train_set3, batch_size=8, shuffle=True)\n",
    "val_loader3 = DataLoader(val_set3, batch_size=8)\n",
    "test_loader3 = DataLoader(test_set3, batch_size=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ac9c0",
   "metadata": {},
   "source": [
    "The following is the domain adaptation data partitioning code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd742f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader \n",
    "# Load the dataset\n",
    "dataset1 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX\")  # Source domain\n",
    "dataset2 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX2\")  # Target domain\n",
    "dataset3 = HeteroGraphDataset(\"G:\\XXXX\\XXXXX\\XXXXXX3\")  # Target domain\n",
    "\n",
    "# Define the Source domain and Target domain labels for each task.\n",
    "label_mapping = {\n",
    "    'T0B': {\n",
    "        'source': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 1\n",
    "    },\n",
    "    'T1B': {\n",
    "        'source': [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.875\n",
    "    },\n",
    "    'T2B': {\n",
    "        'source': [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.8125\n",
    "    },\n",
    "    'T3B': {\n",
    "        'source': [0, 1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,15],\n",
    "        'intersection_ratio': 0.8125\n",
    "    },\n",
    "    'T4B': {\n",
    "        'source': [0, 1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.6875\n",
    "    },\n",
    "    'T5B': {\n",
    "        'source': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.6875\n",
    "    },\n",
    "    'T6B': {\n",
    "        'source': [0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.5\n",
    "    },\n",
    "    'T7B': {\n",
    "        'source': [0, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.3125\n",
    "    },\n",
    "    'T8B': {\n",
    "        'source': [0, 12, 13, 14, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.125\n",
    "    },\n",
    "    'T9B': {\n",
    "        'source': [0, 5],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.125\n",
    "    },\n",
    "    'T10B': {\n",
    "        'source': [0, 11],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.125\n",
    "    },\n",
    "    'T11B': {\n",
    "        'source': [0, 15],\n",
    "        'target': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "        'intersection_ratio': 0.125\n",
    "    }\n",
    "}\n",
    "# Extract source domain and target domain data\n",
    "source_domain_data_train = []\n",
    "source_domain_data_val = []\n",
    "target_domain_data_test = []\n",
    "\n",
    "# ====== Define Tag Filtering Task (Using T1B as an Example) ======\n",
    "task_name = 'T11B'\n",
    "label_filter = label_mapping[task_name]\n",
    "source_labels = label_filter['source']\n",
    "target_labels = label_filter['target']\n",
    "\n",
    "# ====== Data Set Partitioning Ratio Settings ======\n",
    "def get_split_lengths(dataset):\n",
    "    n = len(dataset)\n",
    "    return int(0.7 * n), int(0.15 * n), n - int(0.7 * n) - int(0.15 * n)\n",
    "\n",
    "train_len1, val_len1, test_len1 = get_split_lengths(dataset1)\n",
    "train_len2, val_len2, test_len2 = get_split_lengths(dataset2)\n",
    "train_len3, val_len3, test_len3 = get_split_lengths(dataset3)\n",
    "\n",
    "# ====== Dataset Partitioning ======\n",
    "train_set1, val_set1, test_set1 = random_split(dataset1, [train_len1, val_len1, test_len1], generator=torch.Generator().manual_seed(42))\n",
    "train_set2, val_set2, test_set2 = random_split(dataset2, [train_len2, val_len2, test_len2], generator=torch.Generator().manual_seed(42))\n",
    "train_set3, val_set3, test_set3 = random_split(dataset3, [train_len3, val_len3, test_len3], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# ====== Label Filtering Logic: Filter image samples based solely on y (category label) ======\n",
    "for dataset, train_indices in zip([dataset1,dataset2, dataset3], [train_set1.indices, train_set2.indices, train_set3.indices]):\n",
    "    source_domain_data_train.extend([\n",
    "        dataset[idx] for idx in train_indices if dataset[idx].y.item() in source_labels\n",
    "    ])\n",
    "\n",
    "for dataset, val_indices in zip([dataset1,dataset2, dataset3], [val_set1.indices, val_set2.indices, val_set3.indices]):\n",
    "    source_domain_data_val.extend([\n",
    "        dataset[idx] for idx in val_indices if dataset[idx].y.item() in source_labels\n",
    "    ])\n",
    "\n",
    "# Target domain: Select only images whose labels are present in target_labels (from dataset2 and dataset3).\n",
    "\n",
    "for dataset, test_indices in zip([dataset1,dataset2, dataset3], [test_set1.indices, test_set2.indices, test_set3.indices]):\n",
    "    target_domain_data_test.extend([\n",
    "        dataset[idx] for idx in test_indices if dataset[idx].y.item() in target_labels\n",
    "    ])\n",
    "\n",
    "# ====== Build DataLoader (batch processing diagram) ======\n",
    "train_loader_source = DataLoader(source_domain_data_train, batch_size=8, shuffle=True, drop_last=True)\n",
    "val_loader_source   = DataLoader(source_domain_data_val, batch_size=8, drop_last=True)\n",
    "test_loader_target  = DataLoader(target_domain_data_test, batch_size=8, drop_last=True)\n",
    "\n",
    "# ====== Print Information Confirmation ======\n",
    "print(f\"Current Task: {task_name}\")\n",
    "print(f\"Tag filtering is enabled: Source={source_labels} | Target={target_labels}\")\n",
    "print(f\"Source Domain Train Size: {len(source_domain_data_train)}\")\n",
    "print(f\"Source Domain Validation Size: {len(source_domain_data_val)}\")\n",
    "print(f\"Target Domain Test Size: {len(target_domain_data_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a9f288",
   "metadata": {},
   "source": [
    "Visualization of Graph Construction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "sample = dataset1[0]\n",
    "\n",
    "G = nx.Graph()\n",
    "node_colors = {}\n",
    "node_labels = {}\n",
    "edge_colors = []\n",
    "\n",
    "# Color and Legend Name\n",
    "color_palette = {\n",
    "    'Displacement': '#1f77b4',\n",
    "    'Acceleration': '#ff7f0e',\n",
    "    'Acoustic': '#2ca02c',\n",
    "    'Telemetric stress': '#d62728',\n",
    "    'Patch stress': '#9467bd',\n",
    "    'Supernode': '#8c564b',\n",
    "    'bottom_layer': '#e377c2',\n",
    "    'global_supernode': '#8c564b'  \n",
    "}\n",
    "\n",
    "edge_color_palette = {\n",
    "    'Frequency edges': '#17becf',\n",
    "    'Frequency-Hop edges': '#bcbd22',\n",
    "    'Modality edges': '#e377c2',\n",
    "    'Modality supernode edges': '#d8b79a',\n",
    "    'Space edges': '#7f7f7f'\n",
    "}\n",
    "\n",
    "# Establish a mapping\n",
    "node_type_mapping = {\n",
    "    'displacement': 'Displacement',\n",
    "    'acceleration': 'Acceleration',\n",
    "    'sound': 'Acoustic',\n",
    "    'blade_stress': 'Telemetric stress',\n",
    "    'casing_stress': 'Patch stress',\n",
    "}\n",
    "edge_type_mapping = {\n",
    "    'freq_edge': 'Frequency edges',\n",
    "    'hop_edge': 'Frequency-Hop edges',\n",
    "    'modality_edge': 'Modality edges',\n",
    "    'supernode_edge': 'Modality supernode edges',\n",
    "    'inter_supernode_edge': 'Space edges'\n",
    "}\n",
    "\n",
    "super_nodes_set = set()\n",
    "modality_supernodes = []\n",
    "\n",
    "# Add node\n",
    "for node_type in sample.node_types:\n",
    "    num_nodes = sample[node_type].x.size(0)\n",
    "    for i in range(num_nodes):\n",
    "        node_id = f\"{node_type}_{i}\"\n",
    "        is_super = (i == num_nodes - 1)\n",
    "        mapped_type = node_type_mapping.get(node_type, node_type)\n",
    "        color = color_palette['Supernode'] if is_super else color_palette[mapped_type]\n",
    "        label = f\"{mapped_type}_super\" if is_super else mapped_type\n",
    "        G.add_node(node_id)\n",
    "        node_colors[node_id] = color\n",
    "        node_labels[node_id] = label\n",
    "        if is_super:\n",
    "            super_nodes_set.add(node_id)\n",
    "            modality_supernodes.append(node_id)\n",
    "\n",
    "\n",
    "# Add edge\n",
    "for edge_type in sample.edge_types:\n",
    "    src_type, rel_type, dst_type = edge_type\n",
    "    edge_index = sample[edge_type].edge_index\n",
    "    rel_label = edge_type_mapping.get(rel_type, rel_type)\n",
    "    color = edge_color_palette.get(rel_label, 'black')\n",
    "    for s, d in zip(edge_index[0].tolist(), edge_index[1].tolist()):\n",
    "        src_id = f\"{src_type}_{s}\"\n",
    "        dst_id = f\"{dst_type}_{d}\"\n",
    "        G.add_edge(src_id, dst_id, rel_type=rel_type)\n",
    "        edge_colors.append(color)\n",
    "\n",
    "\n",
    "for i in range(len(modality_supernodes)):\n",
    "    for j in range(i + 1, len(modality_supernodes)):\n",
    "        G.add_edge(modality_supernodes[i], modality_supernodes[j], rel_type=\"inter_supernode_edge\")\n",
    "        edge_colors.append(edge_color_palette['Space edges'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "node_color_list = [node_colors[n] for n in G.nodes()]\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_color_list, node_size=40)\n",
    "nx.draw_networkx_edges(G, pos, edge_color=edge_colors, width=0.6)\n",
    "\n",
    "\n",
    "supernode_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('rel_type') == 'supernode_edge']\n",
    "inter_supernode_edges = [(u, v) for u, v, attr in G.edges(data=True) if attr.get('rel_type') == 'inter_supernode_edge']\n",
    "\n",
    "nx.draw_networkx_edges(G, pos, edgelist=supernode_edges, edge_color=edge_color_palette['Modality supernode edges'], width=0.6)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=inter_supernode_edges, edge_color=edge_color_palette['Space edges'], width=0.6)\n",
    "\n",
    "\n",
    "filtered_node_legend = [\n",
    "    mlines.Line2D([], [], color='white', marker='o', markerfacecolor=c, markersize=6, label=nt)\n",
    "    for nt, c in color_palette.items()\n",
    "    if nt not in ['bottom_layer', 'global_supernode']\n",
    "]\n",
    "edge_legend = [\n",
    "    mlines.Line2D([], [], color=c, label=et, linewidth=1.2)\n",
    "    for et, c in edge_color_palette.items()\n",
    "]\n",
    "\n",
    "plt.legend(\n",
    "    handles=filtered_node_legend + edge_legend,\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, 0.07),\n",
    "    ncol=3,\n",
    "    fontsize=14,\n",
    "    frameon=False,\n",
    "    handlelength=1.0,\n",
    "    handletextpad=0.4,\n",
    "    columnspacing=0.8\n",
    ")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.subplots_adjust(top=1, bottom=0, left=0, right=1)\n",
    "plt.savefig(\"graph_5supernodes_interconnected.png\", dpi=1800, bbox_inches='tight', pad_inches=0)\n",
    "plt.savefig(\"graph_5supernodes_interconnected.jpg\", dpi=1800, bbox_inches='tight', pad_inches=0)\n",
    "plt.savefig(\"graph_5supernodes_interconnected.tiff\", dpi=1800, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef8d2f",
   "metadata": {},
   "source": [
    "Main Content of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78be1f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HGTConv, global_mean_pool\n",
    "\n",
    "# DropEdge\n",
    "def drop_edge(edge_index, drop_prob=0.2):\n",
    "    num_edges = edge_index.size(1)\n",
    "    if num_edges == 0:\n",
    "        return edge_index\n",
    "\n",
    "    keep_ratio = max(1.0 - drop_prob, 0.7)\n",
    "    num_keep = max(int(num_edges * keep_ratio), int(num_edges * 0.7))\n",
    "\n",
    "    perm = torch.randperm(num_edges, device=edge_index.device)[:num_keep]\n",
    "    return edge_index[:, perm]\n",
    "\n",
    "# DropFeature\n",
    "def drop_feature(x, drop_prob=0.2, attention_weight=None):\n",
    "    if attention_weight is not None:\n",
    "        att_prob = torch.sigmoid(attention_weight).unsqueeze(1).expand_as(x)\n",
    "        mask = torch.rand_like(x) > (drop_prob * (1 - att_prob))  # ‰øùÁïôÈ´òÊùÉÈáç\n",
    "    else:\n",
    "        mask = torch.rand_like(x) > drop_prob\n",
    "    return x * mask.float()\n",
    "\n",
    "# Modal Attention\n",
    "class ModalityAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_modalities):\n",
    "        super().__init__()\n",
    "        self.att_weight = nn.Parameter(torch.randn(num_modalities))\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.gate_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, modality_ids):\n",
    "        alpha = F.softmax(self.att_weight, dim=0)\n",
    "        weight = alpha[modality_ids]\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        return self.proj(x) * weight.unsqueeze(1) * gate, alpha\n",
    "\n",
    "# Frequency Attention\n",
    "class FrequencyAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_freqs):\n",
    "        super().__init__()\n",
    "        self.att_weight = nn.Parameter(torch.randn(num_freqs))\n",
    "        self.proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.gate_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x, freq_ids):\n",
    "        gamma = F.softmax(self.att_weight, dim=0)\n",
    "        weight = gamma[freq_ids]\n",
    "        gate = torch.sigmoid(self.gate_proj(x))\n",
    "        return self.proj(x) * weight.unsqueeze(1) * gate, gamma\n",
    "\n",
    "# Model Structure\n",
    "class HGTWithContrastive(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, metadata,\n",
    "                 num_modalities, num_freqs, heads=4, dropout=0.3,\n",
    "                 dropedge_prob=0.2, dropfeat_prob=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropedge_prob = dropedge_prob\n",
    "        self.dropfeat_prob = dropfeat_prob\n",
    "        self.metadata = metadata\n",
    "\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            ntype: nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ) for ntype in metadata[0]\n",
    "        })\n",
    "\n",
    "        self.hgt1 = HGTConv(hidden_dim, hidden_dim, metadata=metadata, heads=heads)\n",
    "        self.hgt2 = HGTConv(hidden_dim, hidden_dim, metadata=metadata, heads=heads)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.mod_att = ModalityAttention(hidden_dim, num_modalities)\n",
    "        self.freq_att = FrequencyAttention(hidden_dim, num_freqs)\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, batch_dict, modality_ids, freq_ids, training=True):\n",
    "        alpha_dict = {}\n",
    "        gamma_dict = {}\n",
    "        for ntype in x_dict:\n",
    "            x = self.embeddings[ntype](x_dict[ntype])   # ÊòæÂºèÊâßË°å Linear(28->64)\n",
    "            _, alpha = self.mod_att(torch.zeros_like(x), modality_ids[ntype])\n",
    "            _, gamma = self.freq_att(torch.zeros_like(x), freq_ids[ntype])\n",
    "            alpha_dict[ntype] = alpha.detach()\n",
    "            gamma_dict[ntype] = gamma.detach()\n",
    "\n",
    "        if training:\n",
    "            x_embed = {\n",
    "                ntype: drop_feature(\n",
    "                    self.embeddings[ntype](x),\n",
    "                    self.dropfeat_prob,\n",
    "                    attention_weight=(alpha_dict[ntype][modality_ids[ntype]] + gamma_dict[ntype][freq_ids[ntype]]) / 2\n",
    "                )\n",
    "                for ntype, x in x_dict.items()\n",
    "            }\n",
    "        else:\n",
    "            x_embed = {\n",
    "                ntype: self.embeddings[ntype](x) for ntype, x in x_dict.items()\n",
    "            }\n",
    "\n",
    "        x1 = self.hgt1(x_embed, edge_index_dict)  \n",
    "\n",
    "    \n",
    "        if training:\n",
    "            edge_index_dict_dropped = {\n",
    "                k: drop_edge(v, self.dropedge_prob) if k[1] in ['modality', 'supmod'] else v\n",
    "                for k, v in edge_index_dict.items()\n",
    "            }\n",
    "        else:\n",
    "            edge_index_dict_dropped = edge_index_dict\n",
    "\n",
    "        x2 = self.hgt2(x1, edge_index_dict_dropped)\n",
    "\n",
    "        x_stack = {\n",
    "            ntype: torch.stack([x1[ntype], x2[ntype]], dim=1)\n",
    "            for ntype in x1\n",
    "        }\n",
    "        x_fused = {\n",
    "            ntype: self.gru(x_stack[ntype])[0][:, -1, :]\n",
    "            for ntype in x_stack\n",
    "        }\n",
    "\n",
    "        features = [x_fused[ntype] for ntype in x_fused]\n",
    "        x_all = torch.cat(features, dim=0)\n",
    "\n",
    "        all_mod = torch.cat([modality_ids[ntype] for ntype in x_fused], dim=0)\n",
    "        all_freq = torch.cat([freq_ids[ntype] for ntype in x_fused], dim=0)\n",
    "        all_batch = torch.cat([batch_dict[ntype] for ntype in x_fused], dim=0)\n",
    "\n",
    "        x_all = x_all + self.mod_att(x_all, all_mod)[0] + self.freq_att(x_all, all_freq)[0]\n",
    "        x_pool = self.pool(x_all, all_batch)\n",
    "\n",
    "        return self.classifier(x_pool)\n",
    "\n",
    "    def extract_feature(self, x_dict, edge_index_dict, batch_dict, modality_ids, freq_ids, training=True):\n",
    "        return self.forward(x_dict, edge_index_dict, batch_dict, modality_ids, freq_ids, training=training)\n",
    "    def extract_multi_stage_features(self, x_dict, edge_index_dict, batch_dict, modality_ids, freq_ids, training=False):\n",
    "        stage_outputs = {}\n",
    "\n",
    "        embed_dict = {ntype: self.embeddings[ntype](x_dict[ntype]) for ntype in x_dict}\n",
    "\n",
    "        x1 = self.hgt1(embed_dict, edge_index_dict)\n",
    "        stage_outputs[\"HGT1\"] = torch.cat([x1[ntype] for ntype in x1], dim=0)\n",
    "\n",
    "        x2 = self.hgt2(x1, edge_index_dict)\n",
    "        stage_outputs[\"HGT2\"] = torch.cat([x2[ntype] for ntype in x2], dim=0)\n",
    "\n",
    "        x_stack = {ntype: torch.stack([x1[ntype], x2[ntype]], dim=1) for ntype in x1}\n",
    "        x_gru = {ntype: self.gru(x_stack[ntype])[0][:, -1, :] for ntype in x_stack}\n",
    "        stage_outputs[\"GRU\"] = torch.cat([x_gru[ntype] for ntype in x_gru], dim=0)\n",
    "\n",
    "        all_mod = torch.cat([modality_ids[ntype] for ntype in x_gru], dim=0)\n",
    "        all_freq = torch.cat([freq_ids[ntype] for ntype in x_gru], dim=0)\n",
    "        all_batch = torch.cat([batch_dict[ntype] for ntype in x_gru], dim=0)\n",
    "\n",
    "        x_all = torch.cat([x_gru[ntype] for ntype in x_gru], dim=0)\n",
    "        x_all_att = x_all + self.mod_att(x_all, all_mod)[0] + self.freq_att(x_all, all_freq)[0]\n",
    "        stage_outputs[\"Attention\"] = x_all_att\n",
    "\n",
    "        x_pool = self.pool(x_all_att, all_batch)\n",
    "        stage_outputs[\"Pool\"] = x_pool\n",
    "\n",
    "        x_hidden = self.classifier[0](x_pool)\n",
    "        stage_outputs[\"Classifier\"] = x_hidden\n",
    "\n",
    "        return stage_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch_geometric\n",
    "\n",
    "def graph_augment(data, drop_edge_prob=0.2, drop_feat_prob=0.2):\n",
    "    # Create a data copy\n",
    "    data = copy.deepcopy(data)\n",
    "\n",
    "    # DropEdge\n",
    "    for edge_type in data.edge_index_dict:\n",
    "        edge_index = data.edge_index_dict[edge_type]\n",
    "        num_edges = edge_index.size(1)\n",
    "        mask = torch.rand(num_edges, device=edge_index.device) > drop_edge_prob\n",
    "        data.edge_index_dict[edge_type] = edge_index[:, mask]\n",
    "\n",
    "    # DropFeature\n",
    "    for ntype in data.x_dict:\n",
    "        x = data.x_dict[ntype]\n",
    "        mask = torch.rand_like(x) > drop_feat_prob\n",
    "        data.x_dict[ntype] = x * mask.float()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def contrastive_loss(z1, z2, temperature=0.5):\n",
    "    \"\"\"\n",
    "    Compute NT-Xent contrast loss\n",
    "    z1, z2: Graph embeddings under two augmented views (batch_size, dim)\n",
    "    \"\"\"\n",
    "    z1 = F.normalize(z1, dim=1)\n",
    "    z2 = F.normalize(z2, dim=1)\n",
    "\n",
    "    batch_size = z1.size(0)\n",
    "    representations = torch.cat([z1, z2], dim=0)  # (2B, D)\n",
    "    similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "\n",
    "    # Construct labels (positive samples on the diagonal)\n",
    "    labels = torch.arange(batch_size, device=z1.device)\n",
    "    labels = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    # Block diagonal (self vs. self)\n",
    "    mask = torch.eye(2 * batch_size, device=z1.device).bool()\n",
    "    similarity_matrix = similarity_matrix.masked_fill(mask, -9e15)\n",
    "\n",
    "    # scale by temperature and compute loss\n",
    "    similarity_matrix = similarity_matrix / temperature\n",
    "    loss = F.cross_entropy(similarity_matrix, labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2473bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the MMD Loss Function\n",
    "def compute_mmd(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    \"\"\"Maximum Mean Discrepancy (MMD) loss\"\"\"\n",
    "    batch_size = source.size(0)\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    total0 = total.unsqueeze(0).expand(total.size(0), -1, -1)\n",
    "    total1 = total.unsqueeze(1).expand(-1, total.size(0), -1)\n",
    "    L2_distance = ((total0 - total1)**2).sum(2)\n",
    "\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (batch_size ** 2 - batch_size)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    kernels = sum(kernel_val)\n",
    "\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY - YX)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9797b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the SupCon Contrast Loss Function\n",
    "def supcon_loss(features, labels, temperature=0.07):\n",
    "    \"\"\"Supervised Contrastive Loss\"\"\"\n",
    "    device = features.device\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.T).float().to(device)\n",
    "\n",
    "    features = F.normalize(features, dim=1)\n",
    "    similarity_matrix = torch.div(torch.matmul(features, features.T), temperature)\n",
    "\n",
    "    logits_max, _ = torch.max(similarity_matrix, dim=1, keepdim=True)\n",
    "    logits = similarity_matrix - logits_max.detach()\n",
    "    exp_logits = torch.exp(logits) * (1 - torch.eye(labels.size(0), device=device))\n",
    "    log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-12)\n",
    "\n",
    "    mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-12)\n",
    "    loss = -mean_log_prob_pos.mean()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ca308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training main loop (main task + self-supervised contrastive learning, no domain_id required)\n",
    "def train_one_epoch(model, loader, optimizer, criterion_cls,\n",
    "                    contrastive_weight=0.5, mmd_weight=0.0,\n",
    "                    mode='DG', use_supcon=False):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(next(model.parameters()).device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Primary Task Output\n",
    "        logits = model(\n",
    "            x_dict=batch.x_dict,\n",
    "            edge_index_dict=batch.edge_index_dict,\n",
    "            batch_dict=batch.batch_dict,\n",
    "            modality_ids={k: batch[k].modality_ids for k in batch.node_types},\n",
    "            freq_ids={k: batch[k].freq_ids for k in batch.node_types},\n",
    "            training=True\n",
    "        )\n",
    "\n",
    "        # Comparison View\n",
    "        aug1 = graph_augment(batch, drop_edge_prob=0.2, drop_feat_prob=0.2)\n",
    "        aug2 = graph_augment(batch, drop_edge_prob=0.2, drop_feat_prob=0.2)\n",
    "\n",
    "        z1 = model.extract_feature(\n",
    "            x_dict=aug1.x_dict,\n",
    "            edge_index_dict=aug1.edge_index_dict,\n",
    "            batch_dict=aug1.batch_dict,\n",
    "            modality_ids={k: aug1[k].modality_ids for k in aug1.node_types},\n",
    "            freq_ids={k: aug1[k].freq_ids for k in aug1.node_types},\n",
    "            training=True\n",
    "        )\n",
    "        z2 = model.extract_feature(\n",
    "            x_dict=aug2.x_dict,\n",
    "            edge_index_dict=aug2.edge_index_dict,\n",
    "            batch_dict=aug2.batch_dict,\n",
    "            modality_ids={k: aug2[k].modality_ids for k in aug2.node_types},\n",
    "            freq_ids={k: aug2[k].freq_ids for k in aug2.node_types},\n",
    "            training=True\n",
    "        )\n",
    "\n",
    "        # Select Contrastive or SupCon\n",
    "        if use_supcon:\n",
    "            labels = batch.y.repeat(2)  # Êâ©Â±ïÂåπÈÖç z1/z2 ÂêàÂπ∂ÂêéÊ†áÁ≠æ\n",
    "            z_all = torch.cat([z1, z2], dim=0)\n",
    "            loss_cl = supcon_loss(z_all, labels)\n",
    "        else:\n",
    "            loss_cl = contrastive_loss(z1, z2)\n",
    "\n",
    "        loss_cls = criterion_cls(logits, batch.y)\n",
    "        loss = loss_cls + contrastive_weight * loss_cl\n",
    "\n",
    "        # Adding MMD in DA mode (requires domain_id)\n",
    "        if mode == \"DA\" and hasattr(batch, \"domain_ids\"):\n",
    "            z_feat = model.extract_feature(\n",
    "                x_dict=batch.x_dict,\n",
    "                edge_index_dict=batch.edge_index_dict,\n",
    "                batch_dict=batch.batch_dict,\n",
    "                modality_ids={k: batch[k].modality_ids for k in batch.node_types},\n",
    "                freq_ids={k: batch[k].freq_ids for k in batch.node_types},\n",
    "                training=False\n",
    "            )\n",
    "            domain_ids = torch.cat([batch[k].domain_ids for k in batch.node_types], dim=0)\n",
    "            source = z_feat[domain_ids == 0]\n",
    "            target = z_feat[domain_ids != 0]\n",
    "            if len(source) > 0 and len(target) > 0:\n",
    "                loss_mmd = compute_mmd(source, target)\n",
    "                loss += mmd_weight * loss_mmd\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    return total_loss / len(loader), acc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Verification Function (Main Task Only)\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(model.classifier[0].weight.device)\n",
    "        logits = model(\n",
    "            x_dict=batch.x_dict,\n",
    "            edge_index_dict=batch.edge_index_dict,\n",
    "            batch_dict=batch.batch_dict,\n",
    "            modality_ids={k: batch[k].modality_ids for k in batch.node_types},\n",
    "            freq_ids={k: batch[k].freq_ids for k in batch.node_types},\n",
    "            training=False\n",
    "        )\n",
    "        loss = criterion(logits, batch.y)\n",
    "        total_loss += loss.item()\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "    return total_loss / len(loader), correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=50, lr=1e-3, \n",
    "                contrastive_weight=0.5, patience=20,\n",
    "                mode='DG',              # Mode Switching Support (‚ÄúDG‚Äù / ‚ÄúDA‚Äù)\n",
    "                use_supcon=False,        # Should SupCon be used?\n",
    "                mmd_weight=1.0):        # MMD Loss Weight (Effective only in DA mode)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5, verbose=True)\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    save_path = \"your_model_new.pth\"\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        try:\n",
    "            train_loss, train_acc = train_one_epoch(\n",
    "                model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                criterion_cls,\n",
    "                contrastive_weight=contrastive_weight,\n",
    "                mmd_weight=mmd_weight,\n",
    "                mode=mode,\n",
    "                use_supcon=use_supcon\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[Epoch {epoch:02d}] ‚ö†Ô∏è Training failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion_cls)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f\"[Epoch {epoch:02d}] ‚úÖ Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"üì¶ Best model saved at epoch {epoch} with Val Acc: {val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"üõë Early stopping at epoch {epoch}.\")\n",
    "                break\n",
    "\n",
    "    print(f\"üéØ Best Validation Accuracy: {best_val_acc:.4f}\")\n",
    "    # model.load_state_dict(torch.load(save_path))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "\n",
    "model = HGTWithContrastive(\n",
    "    input_dim=28,                         \n",
    "    hidden_dim=64,\n",
    "    output_dim=16,                        \n",
    "    metadata=dataset1[0].metadata(),     \n",
    "    num_modalities=5,\n",
    "    num_freqs=7,\n",
    "    # num_layers=2,\n",
    "    heads=4,\n",
    "    dropout=0.5,\n",
    "    dropedge_prob=0.2,\n",
    "    dropfeat_prob=0.2                    \n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"üì¶ Model initialized with {total_params:,} trainable parameters.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020653f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(\n",
    "    model,\n",
    "    train_loader=train_loader3,\n",
    "    val_loader=val_loader3,\n",
    "    num_epochs=50,\n",
    "    lr=1e-3,\n",
    "    contrastive_weight=0.5,\n",
    "    patience=15,\n",
    "    mode='DG',                 \n",
    "    use_supcon=False,           \n",
    "    mmd_weight=1.0             \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ba4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader  \n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, title, filename):\n",
    "    plt.figure(figsize=(3.5, 3))\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', cbar=False,\n",
    "                xticklabels=np.arange(cm.shape[1]),\n",
    "                yticklabels=np.arange(cm.shape[0]),\n",
    "                annot_kws={\"fontsize\": 9})  # ‚úÖ Â≠óÂè∑ËÆæÁΩÆ‰∏∫11\n",
    "    plt.xlabel(\"Predicted label\", fontsize=10, fontname='Times New Roman')\n",
    "    plt.ylabel(\"True label\", fontsize=10, fontname='Times New Roman')\n",
    "    # plt.title(title, fontsize=13, fontname='Times New Roman')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{filename}.png\", dpi=1200, bbox_inches='tight')\n",
    "    plt.savefig(f\"{filename}.jpg\", dpi=1200, bbox_inches='tight')\n",
    "    plt.savefig(f\"{filename}.tiff\", dpi=1200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model_with_cm(model, loader, title, filename, device='cpu'):\n",
    "    model.to(device).eval()\n",
    "    correct, total = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for batch in loader:   \n",
    "        batch = batch.to(device)\n",
    "        logits = model(\n",
    "            x_dict=batch.x_dict,\n",
    "            edge_index_dict=batch.edge_index_dict,\n",
    "            batch_dict=batch.batch_dict,\n",
    "            modality_ids={k: batch[k].modality_ids for k in batch.node_types},\n",
    "            freq_ids={k: batch[k].freq_ids for k in batch.node_types},\n",
    "            training=False\n",
    "        )\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += (pred == batch.y).sum().item()\n",
    "        total += batch.y.size(0)\n",
    "\n",
    "        y_true.extend(batch.y.detach().cpu().tolist())\n",
    "        y_pred.extend(pred.detach().cpu().tolist())\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"{title} ‚úÖ Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plot_confusion_matrix(cm, title, filename)\n",
    "\n",
    "    return acc, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae66866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.loader import DataLoader  \n",
    "\n",
    "model.load_state_dict(torch.load(\"your_model_new.pth\", map_location='cpu'))\n",
    "\n",
    "# Test Load 1\n",
    "acc1, cm1 = test_model_with_cm(model, DataLoader(dataset1), \"Test Load 1\", \"T1_confusion_load1\")\n",
    "\n",
    "# Test Load 2\n",
    "acc2, cm2 = test_model_with_cm(model, DataLoader(dataset2), \"Test Load 2\", \"T1_confusion_load2\")\n",
    "\n",
    "# Test Load 3\n",
    "acc3, cm3 = test_model_with_cm(model, test_loader3, \"Test Load 3\", \"T1_confusion_load3\")\n",
    "\n",
    "# # test_model(model, test_loader1)\n",
    "# test_model(model, DataLoader(dataset1))\n",
    "\n",
    "# # test_model(model, test_loader2)\n",
    "# test_model(model, DataLoader(dataset2))\n",
    "\n",
    "# test_model(model, test_loader3)\n",
    "# # test_model(model, DataLoader(dataset3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
